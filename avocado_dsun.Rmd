---
title: "Limpieza y análisis de datos"
author: "David Sun"
date: "12/5/2022"
output: pdf_document
lang: es-Es
toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)
options(warn=-1)
library(ggplot2) 
library(corrplot)
library(nortest)
library(caTools) # train/test
library(car)
library(randomForest)
library(hydroGOF) # rmse
library(e1071) # svm
library(caret) # r2
```
\pagebreak
# \textcolor{blue}{1. Descripción del dataset}

Se elige un dataset del repositorio Kaggle, en especial llamado **Avocado Prices** [(link)](https://www.kaggle.com/datasets/neuromusic/avocado-prices).

Este dataset nos proviene información sobre la venta minorista en las diferentes regiones de EE.UU de los aguacates de la variedad Hass, sin incluir las otras variedades entre el 4 de enero de 2015 hasta el 25 de marzo de 2018. 

```{r}
avocado <- read.csv("avocado.csv")
head(avocado, n = 3)
```
Revisamos los tipos de datos:
```{r}
sapply(avocado, class)
```
Vemos un resumen de las variables numéricas:
```{r}
summary(avocado[, c("AveragePrice", "Total.Volume", "X4046", "X4225",
                    "X4770", "Total.Bags", "Small.Bags", "Large.Bags",
                    "XLarge.Bags")])
```
Vamos a repasar las diferentes columnas:

- X: índice que se repite cada 51 observaciones por fecha, región, creo que no nos aporta nada y se borrará en este análisis.
- Date: la fecha de la observación.
- AveragePrice: el precio medio de venta de un aguacate.
- Total.Volume: número total de aguacates vendidos.
- X4046: número de ventas de aguacates pequeños clasificados como 4046 según el Product Lookup codes (PLU).
- X4225: número de ventas de aguacates grandes clasificados como 4225 según el PLU.
- X4770: número de ventas de aguacates extra grandes clasificados como 4770 según el PLU.
- Total.Bags: Número total de bolsas vendidas (cada bolsa hay múltiples aguacates).
- Small.Bags: bolsas vendidas pequeñas.
- Large.Bags: bolsas vendidas grandes.
- XLarge.Bags: bolsas vendidas extra grandes.
- type: orgánico o convencional.
- year: el año.
- region: la región que que se ha hecho la observación.

Para más información sobre los criterios de clasificación de los tamaños de los productos podemos entrar en **International Federation for Produce Standards (IFPS)** [link](https://www.ifpsglobal.com/PLU-Codes).

Con este dataset podemos obtener información sobre la evolución de los precios de los aguacates y también el patrón de consumo en las diferentes regiones de EEUU.

# \textcolor{blue}{2. Integración y selección de los datos de interés a analizar}

Vamos a eliminar la primera columna ya que no podemos extraer ninguna información de ella:
```{r}
avocado = subset(avocado, select = -c(X) )
```

Podriamos eliminar la columna del año y extraer la información de la fecha pero creo que para hacer consultas luego es más fácil, así que vamos a dejar esta columna.

# \textcolor{blue}{3. Limpieza de los datos}

## \textcolor{blue}{3.1. Valores nulos}

Miramos si el dataset tiene algún valor nulo:
```{r}
table(is.na(avocado))
```

## \textcolor{blue}{3.2. Cambio formato datos}

Vamos a cambiar de "character" a "Date" la fecha:
```{r}
avocado$Date <-as.Date(avocado$Date, "%Y-%m-%d") 
    
# Print result
print(class(avocado$Date))
print(avocado$Date[0:10])
```
Pasamos a factor la variable type a factor:
```{r}
avocado$type = as.factor(avocado$type)
print(class(avocado$type))
```
Miramos cuantos factores tiene:
```{r}
levels(avocado$type)
```
## \textcolor{blue}{3.3. Identifica y gestiona los valores extremos}

Hay dos tipo de outliers:

- **Valor centinela**: este tipo de outlier suele ser representación de un valor nulo o desconocido y suele ser un valor extraño en el rango de valores que puede tener la variable por ejemplo -1 como las horas que pasan la gente en redes sociales.

- **Valor atípico propiamente**: es el valor atípico propiamente dicho, puede ser que sea un valor legítimo extremo o un valor extremo que pued ser un error, este valor hay que tratarla o no dependiendo de la situación, ya que puede afectar a los estimadores de las tendencias centrales y de dispersión como la media o la desviación estándar. Una también podemos usar estimadores resistentes a estos valores extremos, como la media winsorizada, media recortada o RIC para sustituir a la desviación estándar.

Hay muchas formas de detectar los valores extremos o outliers, en este caso usamos el médodo del Rango Intercuartílico (RIC), el RIc es la diferencia entre el cuartil 3 (Q3) y el cuartil 1 (Q1). clasificamos los outlier con los siguientes criterios:

- Q3 + RIC * 1.5 > outlier

- Q1 - RIC *1.5 < outlier

![RIC](rango.png){width=40%}

Vamos a ver algunas graficas y los outliers:
```{r}
# subset por tipo
avocado_conv <- avocado[avocado$type == "conventional", ] 
avocado_org <- avocado[avocado$type == "organic", ] 

par(mfrow=c(1,3))
boxplot(avocado$AveragePrice ~ avocado$type, horizontal=FALSE, xlab="Type", ylab="Price")
boxplot(log(avocado$Total.Volume) ~ avocado$type, horizontal=FALSE,
        xlab="Type", ylab="Total Sales (in log scale)")
boxplot(log(avocado$Total.Bags) ~ avocado$type ,horizontal=FALSE,
        xlab="Type", ylab="Total bags sold (in log scale)")
```

```{r}
# outliers de aguacate convencional
boxplot.stats(avocado_conv$AveragePrice)$out[1:5]
boxplot.stats(avocado_conv$Total.Bags)$out[1:5]

# outliers de aguacate orgánico
boxplot.stats(avocado_org$AveragePrice)$out[1:5]
boxplot.stats(avocado_org$Total.Bags)$out[1:5]
```
Aunque vemos que hay bastantes outliers, en realidad son valores realistas que realmente son los precios que se ha vendido y las cantidades de estas y no se han de eliminar. 

Podemos ver ya que el precio de los aguacates ecológicos es mayor al de los convencionales y que hay menos ventas totales de las orgánicas.

# \textcolor{blue}{4. Análisis de los datos}

Vamos a ver como se ha comportado las ventas y los precios de los aguacates convencionales en las diferentes regiones de los EEUU:

Podemos ver en la siguiente gráfica un aumento del volumen total de vental en todas las regiones en general desde 2015 hasta 2018 aunque el crecimiento desde 2017 hasta 2018 ha sido menor que los años anteriores. 

También podemos observar las regiones donde se han consumido más aguacate y los que menos.

```{r, fig.width=12, fig.height=15}
ggplot(avocado_conv, aes(x = region, y = Total.Volume, fill = factor(year))) +
geom_bar(stat = "identity",position = "dodge") + 
coord_flip()
```
Ahora miramos la evolucion de los precios de los aguacates convencionales:
```{r, fig.width=7, fig.height=15}
ggplot(avocado, aes(y=region, x=AveragePrice, fill = factor(year))) + geom_boxplot() 
```

Podemos ver que en general en el país no ha subido los precios sino que ha ido fructuando. Vemos que una de las regiones donde el precio subió de forma abrupta fue en San Francisco y en RaleighGreensboro en el año 2017. 

## \textcolor{blue}{4.1. Normalidad y homogeneidad de la varianza}

Vamos a estudiar la normalidad de los precios:
```{r, fig.width=8, fig.height=3}
ggplot(avocado, aes(x=AveragePrice, fill=type)) + geom_density() + facet_wrap(~type) + 
ggtitle("Avocado Price")
```
```{r}
# Test normalidad de Kolmogorov-Smirnov aguacate convencional
lillie.test(avocado_conv$AveragePrice)
```
El test de Kolmogorov-Smirnov es un contraste bilateral donde:

- H0: los datos proceden de una distribución normal.
- H1: los datos no proceden de una distribución normal.

El P valor es la probabilidad de haber obtenido el resultado que hemos obtenido suponiendo que la hipótesis
nula H0 es cierta.
El valor de alfa predeterminado es de 0.05, si P valor es menor a alfa podemos descartar ya la hipótesis nula,
es decir los datos no tienen una distribución normal.
```{r}
# Test normalidad de Kolmogorov-Smirnov aguacate orgánico
lillie.test(avocado_org$AveragePrice)
```
Podemos ver que el precio de los aguacates orgánicos tampoco son normales. Podemos también complementarlo con la visualización con los QQ plots, donde la linea sería la representación de una distribución normal, como vemos los datos no encajan del todo.
```{r}
par(mfrow=c(1,2))
qqnorm(avocado_org$AveragePrice, main=NULL)
qqline(avocado_org$AveragePrice)
title("Q-Q Plot Organic prices")
qqnorm(avocado_conv$AveragePrice, main=NULL)
qqline(avocado_conv$AveragePrice)
title("Q-Q Plot Conventional prices")
```
Tendremos que usar el Test Fligner-Killeen para el análisis de la homocedasticidad ya que no cumplen con la normalidad:
```{r}
fligner.test(AveragePrice  ~ type, data = avocado)
```
Vemos que la p-valor es estadísticamente significativa, rechazando la hipótesis nula de la igualdad de varianzas.


## \textcolor{blue}{4.2. Test de rangos y signos}

Vamos a emplear el Test de rangos y signos como la prueba no paramétrica de dos muestras independientes: 
```{r}
wilcox.test(avocado_org$AveragePrice, avocado_conv$AveragePrice, alternative="greater")
```
Vemos que también el p valor es menor a alfa=0.05, descartando la hipótesis nula de igualdad de mediana, aceptando el precio mayor de los aguacates orgánicos. 

## \textcolor{blue}{4.3. Correlación de Spearman}

```{r}
# encoding variable categóricas 1 como organicas 0 convencionales
avocado$type.encode <- ifelse(avocado$type == "organic",1,0)
```

Vamos a representar una correlación de Spearman:
```{r}
correlation = round(cor(avocado[,c("AveragePrice", "Total.Volume", "X4046", "X4225",
                    "X4770", "Total.Bags", "Small.Bags", "Large.Bags",
                    "XLarge.Bags", "type.encode", "year")], method = "spearman"),2)
corrplot(correlation, method="number", type="upper", number.cex=0.75)
```
Vemos que el tipo de aguacate tiene una correlación positiva de 0.64 con el precio mientras todas las otras variables tiene correlación negativa con el precio medio, siendo el año una variable que casi no tiene correlación con el precio.

## \textcolor{blue}{4.4 Modelos de regresión}

Primero vamos a dividir el dataset en conjunto de entrenamiento/training y de test.
```{r}
set.seed(222222) # un random seed cualquiera 
split = sample.split(avocado$AveragePrice, SplitRatio = 0.8)
training_set = subset(avocado, split == TRUE)
testing_set = subset(avocado, split == FALSE)
```




### \textcolor{blue}{4.4.1. Regresión lineal múltiple}

Modelo de regresión linear múltiple:

En la regresión linear múltiple no siempre el modelo con todas las variables es la mejor, eso es porque no todas las variables aportan información útil al modelo, usaremos el método de: Eliminación hacia atras, que consiste en: 

- 1. Elegir un nivel de significación (SL) para quedar con la variable (0.05 normalmente)
- 2. meter todas las variables modelos a la vez: _All in_
- 3. elegir la variable predictora con p valor más grande, si p valor > SL al paso 4 sino al FIN
- 4. Eliminar variable predictora
- 5. Ajustar el nuevo modelo sin esa variable y repetir paso 3
- FIN: cuando todas las variables tenga que p valor < SL

```{r}
# la función ya se encarga de crear las variables dummies de las variables categóricas
model = lm(AveragePrice ~ Total.Volume + X4046 + X4225 + X4770 + Total.Bags + Small.Bags +
                      Large.Bags + XLarge.Bags + type + year + region, data = training_set)
summary(model)
```
los pasos son muy repetitivos nos lo saltamos y obtenemos el modelo final al aplicar el algoritmo anterior:

```{r}
# se elimina ya de una sola pasada todas las regiones que no tiene poder predictor del precio
region_no_sig = c('Syracuse', 'RaleighGreensboro', 'Chicago','Boston', 'BaltimoreWashington')
training_set_1 = subset(training_set, ! region %in% region_no_sig)
testing_set_1 = subset(testing_set, ! region %in% region_no_sig)
```

```{r}
linear_model = lm(AveragePrice ~ type + year + region, data = training_set_1)
summary(linear_model)$adj.r.squared
```
Vemos que tiene casi el mismo R ajustado (0.558) que el primer modelo pero con menos variables.

Puede ser que el R que nos ha dado sea bajo porque los datos no tenga linealidad, homocedasticidad ni tampoco normalidad de las variables.

Un R ajustado de 0.558 no es un modelo muy bueno. podemos probar con otro modelo de regresión como puede ser como el Random Forest o el Support Vector Maquine.

### \textcolor{blue}{4.4.2. Regresión Random Forest}

```{r}
# elegimos 500 arboles 
rf_model <- randomForest(AveragePrice ~ Total.Volume + X4046 + X4225 + X4770 +
                        Total.Bags + Small.Bags + Large.Bags + XLarge.Bags + type +
                        year + region,
                        data = training_set, 
                        ntree=500, 
                        keep.forest=TRUE,
                        importance=FALSE)
rf_model
```
Vemos que el modelo es bastante bueno, donde las variables independientes explica un 85% de la varianza de la variable precio.

### \textcolor{blue}{4.4.3. Support Vector Maquine}

En el Suport vector maquine podemos elegir diferentes _kernels_ o núcleos para poder clasificar los datos , se ha elegido el que ha tenido la mejor evaluación:
```{r}
svm_model = svm(formula = AveragePrice ~ Total.Volume + X4046 + X4225 + X4770 + 
                          Total.Bags + Small.Bags + Large.Bags + XLarge.Bags +
                          type + year + region, 
                 data = training_set, 
                 type = "eps-regression", 
                 kernel = "radial")
svm_model
```

### \textcolor{blue}{4.4.4. Evaluación de modelos}

Comparación de los modelo con el RMSE (Raíz del error cuadrático medio o Root Mean Square Error)
```{r}
# lineal
pred_linear <- predict(linear_model, testing_set_1[, c('type', 'year', 'region')])
RMSE_linear=rmse(pred_linear,testing_set_1$AveragePrice)
RMSE_linear
```

```{r}
# forest
pred_forest <- predict(rf_model, testing_set[, c("Total.Volume", "X4046", "X4225",
                    "X4770", "Total.Bags", "Small.Bags", "Large.Bags",
                    "XLarge.Bags",'type', 'year', 'region')])
RMSE_rf=rmse(pred_forest,testing_set$AveragePrice)
RMSE_rf
```
```{r}
# svm
pred_svm <- predict(svm_model, testing_set[, c("Total.Volume", "X4046", "X4225",
                    "X4770", "Total.Bags", "Small.Bags", "Large.Bags",
                    "XLarge.Bags",'type', 'year', 'region')])
RMSE_svm=rmse(pred_svm,testing_set$AveragePrice)
RMSE_svm
```
Ya podemos ver que el Random Forest nos ha dado el mejor RMSE y la R^2 ajustado deberia ser también la mejor:

```{r}
# lineal
r2 = R2(testing_set_1$AveragePrice, pred_linear)
r2
```
```{r}
# random forest
r2 = R2(testing_set$AveragePrice, pred_forest)
r2
```

```{r}
# SVM
r2 = R2(testing_set$AveragePrice, pred_svm)
r2
```
Efectivamente el modelo Random forest nos ha dado un R^{2} ajustado de 0.85, un poder de predicción bastante bueno.

## \textcolor{blue}{4.5. Exportar datos}

```{r}
# borrar type ya que tenemos el type.encoded
avocado = subset(avocado, select = -c(type) )

write.csv(avocado,"avocado_finish.csv", row.names = TRUE)
```
\pagebreak

# \textcolor{blue}{5. Conclusiones}

Al estudiar la normalidad y la homocedasticidad, vemos que la distribución de precios ni es normal ni homocedástico por lo tanto solo podemos emplear pruebas no paramétricas que cumplan con estos requisitos, se ha usado el Test de rangos y signos para comparar los precios entre los aguacates orgánicos y no orgánicos y podemos afirmar que estadísticamente el precio de los aguacate orgánicos es mayor a los convencionales, y por lo que se ve también se vende más más cantidad de estas últimas.

En el punto 4.4 cuando evaluamos los diferentes modelos de regresión podemos ver que la regresión lineal en este caso ha dado unos resultados muy pobres dando a entender que nos falta datos relevantes o que el problema no es lineal, mientra que se mejora un poco la RMSE con SVM, la mejora realmente importante viene con el modelo de Random Forest donde también tenemos un R^{2} de 0.85 que nos podrá dar unos resultados bastante fidedignos.

Hay que estacar estos dos últimos modelos son computacionalmente mucho más pesados que la regresión lineal. 